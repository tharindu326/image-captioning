{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Zoomi\\Desktop\\Tharindu\\oulu - masters\\NLP\\project\\myenv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "class ImageEncoder(nn.Module):\n",
    "    def __init__(self, embed_size):\n",
    "        super(ImageEncoder, self).__init__()\n",
    "        self.resnet = nn.Sequential(*list(torchvision.models.resnet50(pretrained=True).children())[:-1])\n",
    "        self.linear = nn.Linear(2048, embed_size)\n",
    "        self.bn = nn.BatchNorm1d(embed_size, momentum=0.01)\n",
    "\n",
    "    def forward(self, images):\n",
    "        features = self.resnet(images)\n",
    "        features = features.view(features.size(0), -1)\n",
    "        out_linear = self.linear(features)\n",
    "        embeddings = self.bn(out_linear)\n",
    "        return embeddings\n",
    "\n",
    "\n",
    "class SemanticEncoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, hidden_size, num_layers):\n",
    "        super(SemanticEncoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.lstm = nn.LSTM(embed_size, hidden_size, num_layers)\n",
    "\n",
    "    def forward(self, texts):\n",
    "        embeddings = self.embedding(texts)\n",
    "        hiddens, _ = self.lstm(embeddings)\n",
    "\n",
    "        return hiddens[:, -1]\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, hidden_size):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.vocab_size = vocab_size\n",
    "        # lstm cell\n",
    "        self.lstm_cell = nn.LSTMCell(input_size=embed_size + hidden_size, hidden_size=hidden_size)\n",
    "        # output fully connected layer\n",
    "        self.fc_out = nn.Linear(in_features=hidden_size, out_features=vocab_size)\n",
    "        # embedding layer\n",
    "        self.embed = nn.Embedding(num_embeddings=vocab_size + hidden_size, embedding_dim=embed_size + hidden_size)\n",
    "        # activations\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, features, captions):\n",
    "        # batch size\n",
    "        batch_size = features.size(0)\n",
    "        # init the hidden and cell states to zeros\n",
    "        hidden_state = torch.zeros((batch_size, self.hidden_size)).to(device)\n",
    "        cell_state = torch.zeros((batch_size, self.hidden_size)).to(device)\n",
    "        # define the output tensor placeholder\n",
    "        outputs = torch.empty((batch_size, captions.size(1), self.vocab_size)).to(device)\n",
    "        # embed the captions\n",
    "        captions_embed = self.embed(captions)\n",
    "        # pass the caption word by word\n",
    "        for t in range(captions.size(1)):\n",
    "            # for the first time step the input is the feature vector\n",
    "            if t == 0:\n",
    "                hidden_state, cell_state = self.lstm_cell(features, (hidden_state, cell_state))\n",
    "            # for the 2nd+ time step, using teacher forcer\n",
    "            else:\n",
    "                hidden_state, cell_state = self.lstm_cell(captions_embed[:, t, :], (hidden_state, cell_state))\n",
    "            # output of the attention mechanism\n",
    "            out = self.fc_out(hidden_state)\n",
    "            # build the output tensor\n",
    "            outputs[:, t, :] = out\n",
    "        return outputs\n",
    "\n",
    "    def sample(self, features, max_seg_length):\n",
    "        \"\"\"Generate captions for given image features using greedy search.\"\"\"\n",
    "        sampled_ids = []\n",
    "        # inputs = features.unsqueeze(1)\n",
    "        batch_size = features.size(0)\n",
    "        hidden_state = torch.zeros((batch_size, self.hidden_size)).to(device)\n",
    "        cell_state = torch.zeros((batch_size, self.hidden_size)).to(device)\n",
    "        for i in range(max_seg_length):\n",
    "            # hiddens, states = self.lstm(inputs, states)  # hiddens: (batch_size, 1, hidden_size)\n",
    "            hidden_state, cell_state = self.lstm_cell(features, (hidden_state, cell_state))\n",
    "            # outputs = self.linear(hiddens.squeeze(1))  # outputs:  (batch_size, vocab_size)\n",
    "            outputs = self.fc_out(hidden_state)\n",
    "            _, predicted = outputs.max(1)  # predicted: (batch_size)\n",
    "            sampled_ids.append(predicted)\n",
    "            features = self.embed(predicted)  # inputs: (batch_size, embed_size)\n",
    "        sampled_ids = torch.stack(sampled_ids, 1)  # sampled_ids: (batch_size, max_seq_length)\n",
    "        return sampled_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import json\n",
    "from nltk.tokenize import word_tokenize\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import pickle\n",
    "from ipynb.fs.full.vocabulary_builder import Vocabulary\n",
    "from ipynb.fs.full.data_loader import ROCODataset\n",
    "\n",
    "\n",
    "class CaptionGenerator:\n",
    "    def __init__(self, vocab_file, embed_size, hidden_size, num_layers, image_encoder_path, semantic_encoder_path,\n",
    "                 decoder_path):\n",
    "        \n",
    "        with open(vocab_file, 'rb') as f:\n",
    "            self.vocab = pickle.load(f)\n",
    "        # convert vocab into index2word format\n",
    "        vocab_size = 2200\n",
    "\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        if torch.cuda.is_available():\n",
    "            map_location = torch.device('cuda')\n",
    "        else:\n",
    "            map_location = torch.device('cpu')\n",
    "\n",
    "        self.image_encoder = ImageEncoder(embed_size).to(self.device)\n",
    "        self.semantic_encoder = SemanticEncoder(vocab_size, embed_size, hidden_size, num_layers).to(self.device)\n",
    "        self.decoder = Decoder(vocab_size, embed_size, hidden_size).to(self.device)\n",
    "\n",
    "        # Load trained weights (assuming you saved them earlier as 'encoder.pth' and 'decoder.pth')\n",
    "        self.image_encoder.load_state_dict(torch.load(image_encoder_path, map_location=map_location))\n",
    "        self.semantic_encoder.load_state_dict(torch.load(semantic_encoder_path, map_location=map_location))\n",
    "        self.decoder.load_state_dict(torch.load(decoder_path, map_location=map_location))\n",
    "\n",
    "        # Set to evaluation mode\n",
    "        self.image_encoder.eval()\n",
    "        self.semantic_encoder.eval()\n",
    "        self.decoder.eval()\n",
    "\n",
    "        # Image preprocessing\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "\n",
    "    def generate_caption(self, image_path, max_length=20):\n",
    "        # Load and preprocess the image\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        image = self.transform(image).unsqueeze(0).to(self.device)\n",
    "\n",
    "        # Get the feature vector from the encoder\n",
    "        features_image = self.image_encoder(image)\n",
    "        # tokens = word_tokenize('CTLA venous phase of donor'.lower())\n",
    "        caption = [self.vocab('<START>')]\n",
    "        # caption.extend([self.vocab.get(token, self.vocab['<UNK>']) for token in tokens])\n",
    "        # caption.append(self.vocab['<END>'])\n",
    "        print(caption)\n",
    "        features_text = self.semantic_encoder(torch.Tensor([caption]).long()[:, :torch.Tensor([caption]).shape[1]])\n",
    "\n",
    "        combined_features = torch.cat((features_image, features_text), dim=1)\n",
    "        print(combined_features.size())\n",
    "\n",
    "        # Initialize the LSTM hidden state with the feature vector\n",
    "        # hidden = combined_features.unsqueeze(0).long()\n",
    "\n",
    "        # Start with the <START> token\n",
    "        # print(self.vocab['<START>'])\n",
    "        # input_token = torch.tensor([[self.vocab['<START>']]], device=self.device).long()\n",
    "        # print('caption size', torch.Tensor([caption]).long().size())\n",
    "        # print('input_token', input_token.size())\n",
    "        gen_caption = []\n",
    "        predicted_token_ids = self.decoder.sample(combined_features, max_seg_length=20)\n",
    "        print(predicted_token_ids)\n",
    "        for id in predicted_token_ids[0].tolist():\n",
    "            word = self.vocab_i2w[id]\n",
    "            if word == '<END>':\n",
    "                break\n",
    "            gen_caption.append(word)\n",
    "        # Generate caption\n",
    "        # for _ in range(max_length):\n",
    "        #     output = self.decoder(combined_features, input_token)\n",
    "        #     predicted_token_ids = torch.argmax(output, dim=2)\n",
    "        #     print('predicted_token_ids', predicted_token_ids.size())\n",
    "        #     # _, predicted = output.max(1)\n",
    "        #     # print(predicted.size())\n",
    "        #     input_token = predicted_token_ids\n",
    "        #     word = self.vocab_i2w[predicted_token_ids.item()]\n",
    "        #     if word == '<END>':\n",
    "        #         break\n",
    "        #     caption.append(word)\n",
    "        #\n",
    "        return ' '.join(gen_caption)\n",
    "\n",
    "    def process_batch(self, batch_size, max_seg_length, json_data_path='selected_dataset/selected_dataset_info.json'):\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "        \n",
    "        test_dataset = ROCODataset(data_json='selected_dataset/selected_dataset_info.json',\n",
    "                                transform=transform,\n",
    "                                vocab=self.vocab,\n",
    "                                dataset_type='test')\n",
    "\n",
    "        test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True,\n",
    "                                collate_fn=ROCODataset.collate_fn,\n",
    "                                num_workers=2)\n",
    "\n",
    "        processed_captions = []\n",
    "        GT_captions = []\n",
    "        for i, (images_val, GT, _) in enumerate(test_loader):\n",
    "            caps = []\n",
    "            for i in range(images_val.size()[0]):\n",
    "                caps.append([self.vocab('<START>')])\n",
    "            captions_val = torch.Tensor(caps).long()\n",
    "            \n",
    "            images = images_val.to(self.device)\n",
    "            image_features = self.image_encoder(images)\n",
    "            text_features = self.semantic_encoder(captions_val[:, :captions_val.shape[1]].to(self.device))\n",
    "            combined_features = torch.cat((image_features, text_features), dim=1)\n",
    "            \n",
    "            # captions_target = captions_val.to(self.device)\n",
    "            # predictions = torch.argmax(self.decoder(combined_features, captions_target), dim=2)\n",
    "            \n",
    "            predictions = self.decoder.sample(combined_features, max_seg_length=max_seg_length)\n",
    "            \n",
    "            for prediction in predictions:\n",
    "                # Convert word_ids to words\n",
    "                sampled_caption = []\n",
    "                for word_id in prediction.detach().numpy():\n",
    "                    word = self.vocab.idx2word[word_id]\n",
    "                    if word != '<start>':\n",
    "                        if word != '<unk>':\n",
    "                            if word != '<end>':\n",
    "                                sampled_caption.append(word)\n",
    "                    if word == '<end>':\n",
    "                        break\n",
    "                image_caption = ' '.join(sampled_caption)\n",
    "                processed_captions.append(image_caption)\n",
    "            \n",
    "            # getting GTs\n",
    "            for gt in GT:\n",
    "                ground_truth_caption = []\n",
    "                for word_id in gt.detach().numpy():\n",
    "                    word = self.vocab.idx2word[word_id]\n",
    "                    if word != '<start>':\n",
    "                        if word != '<unk>':\n",
    "                            if word != '<end>':\n",
    "                                if word != '<pad>':\n",
    "                                    ground_truth_caption.append(word)\n",
    "                image_gt_caption = ' '.join(ground_truth_caption)\n",
    "                GT_captions.append(image_gt_caption)\n",
    "        return processed_captions, GT_captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "within within within within within within within within within cystic mass with irregular septations the head of the pancreas ( arrow ) , mimicking the appearance of a cystic .\n",
      "contours contours contours contours contours contours contours contours ct with multiplanar reconstruction revealed a tumor originating at the lateral and distal part of the trachea and protruding into the\n",
      "contours contours contours contours contours contours contours contours view on a left femoral hernia . arrows show the internal course of the suture\n",
      "contours contours contours contours contours contours contours contours the arrow indicates the compression fracture at the level\n",
      "within within within within within within within within within an ultrasound of the plantar arch was made and found a hypoechoic and homogeneous nodule at the thickness of the plantar fascia with a significant in doppler .\n",
      "contours contours contours contours contours contours contours contours tissue of margins , with acoustic shadow ( arrow ) . in examination : focal fibrosis\n",
      "contours contours contours contours contours contours contours contours ct angiography – pseudoaneurysm of the stump of the gastroduodenal artery – coronal reconstruction\n",
      "contours contours contours contours contours contours contours contours echo ( 2 weeks later ) showing a left ventricle\n",
      "within within within within within within within within within examination of transversal of a crown of group it reveals the characteristic of an fracture ( yellow arrow ) , from the surface towards the layer of opaque and from this layer to the metal , the metal .\n",
      "contours contours contours contours contours contours contours contours coronal ct scan taken two years shows enlarged kidneys filled with numerous cysts and occupying the abdominal and pelvic . note that there are only a few cysts in the liver .\n",
      "contours contours contours contours contours contours contours contours view of prominent in apical segments and less in lateral wall .\n",
      "contours contours contours contours contours contours contours contours x-ray of pacemaker lead to demonstrate lead\n",
      "within within within within within within within within within computed tomography of the thorax demonstrating a small ( 5 mm in diameter ) subpleural nodule within the anterior left upper lobe , which since the previous scan\n",
      "contours contours contours contours contours contours contours contours a typical pattern of distribution of white matter in a t2 mri of a woman affected by\n",
      "contours contours contours contours contours contours contours contours the photo shows the 3d of the ventricular septal defect with a .\n",
      "contours contours contours contours contours contours contours contours preoperative orthopantomogram\n",
      "within within within within within within within within within magnetic resonance imaging ( mri ) of the right knee before the operation . the magnetic resonance imaging of both showed bilateral tibial plateau fracture on medial side and dense bone marrow edema around , signal changes on distal , edema on soft tissues around the knee , and effusion on both\n",
      "contours contours contours contours contours contours contours contours pancreatic lesion of finding . abdominal ultrasound revealed an irregular contoured lesion of cm × cm in the head of pancreas ( m ) , with a calcification at the edge of the mass ( fine arrow ) .\n",
      "contours contours contours contours contours contours contours contours lumbar facet joint injection at . the oblique image shows the position of the needle ( arrow ) .\n",
      "contours contours contours contours contours contours contours contours coronal view .\n",
      "within within within within within within within within within outer retinal ( yellow arrow ) , bright ( red arrow ) , bright ( blue arrow )\n",
      "contours contours contours contours contours contours contours contours computed tomographic scan of the pelvis showing irregularly enhanced uterus ( white arrow ) .\n",
      "contours contours contours contours contours contours contours contours postoperative cholangiogram performed through the hepatic duct stent showing of anastomosis\n",
      "contours contours contours contours contours contours contours contours computed tomography showing multiple lesions ( arrows ) .\n",
      "contours contours contours contours contours contours contours contours axial contrast-enhanced ct section showing a mediastinal extension of the lesion ( arrows ) through the area of the liver .\n",
      "contours contours contours contours contours contours contours contours axial ct showing extensive lytic ( low density ) lesion involving complete body and ramus of mandible\n",
      "contours contours contours contours contours contours contours contours ct scan ( axial view ) .\n",
      "contours contours contours contours contours contours contours contours on the left eye is normal\n",
      "within within within within within within within within within ct image showing a × 14 × 17 cm left retroperitoneal mass with solid and cystic components in the left kidney .\n",
      "contours contours contours contours contours contours contours contours ( ) of cervical length and fetal symphysis distance measured by ultrasound and score\n",
      "contours contours contours contours contours contours contours contours lateral radiograph of the knee .\n",
      "contours contours contours contours contours contours contours contours case 2 :\n",
      "within within within within within within within within within at 24 weeks of gestation . transvaginal ultrasonography revealed loss of hypoechoic appearance of the zone , in the placenta , and bulging of the bladder .\n",
      "contours contours contours contours contours contours contours contours coronal reformatted ct scan of a girl showed and a fracture of the lateral mass ( arrow ) .\n",
      "contours contours contours contours contours contours contours contours contrast-enhanced computed tomography scan showing a hypodense lesion in the sigmoid colon\n",
      "contours contours contours contours contours contours contours contours post operative photo ( case a )\n",
      "within within within within within within within within within . of contrast medium between the mucosal folds small with a pattern . entire of both tube involved ( arrows ) . moderate is seen in the right side ( open arrow ) .\n",
      "contours contours contours contours contours contours contours contours therapy ( ) treatment showing the clinical target volumes , , and isodose lines for gy , gy , and 35 gy .\n",
      "contours contours contours contours contours contours contours contours – after stage ii . antero-posterior view ; contrast through vena ; opacification of both pulmonary arteries through anastomosis\n",
      "contours contours contours contours contours contours contours contours coronal t1-weighted postcontrast mr image showing empty sign due to superior sagittal sinus thrombosis\n",
      "within within within within within within within within within pancreatic presenting as pancreatitis . a linear filling defect is seen all along the pancreatic duct ( straight arrows ) . a stricture is seen in the tail region ( curved arrow ) of pancreatic necrosis . from et al [ 2 ] .\n",
      "contours contours contours contours contours contours contours contours sagittal slice of a magnetic resonance image showing ( arrow ) , the of the tongue in contact with the soft ( arrowheads ) , and narrowing of the air passage .\n",
      "contours contours contours contours contours contours contours contours cxr on initial presentation at other hospital .\n",
      "contours contours contours contours contours contours contours contours , ventral . scale = mm .\n",
      "within within within within within within within within within hyperintense and heterogeneous right adrenal mass ( arrow ) on a t2-weighted mri hyperintense and heterogeneous right adrenal mass ( arrow ) on a t2-weighted mri image .\n",
      "contours contours contours contours contours contours contours contours mri at 47 days after . arrows point to .\n",
      "contours contours contours contours contours contours contours contours multiple hypodense spleen lesions of case 3 .\n",
      "contours contours contours contours contours contours contours contours abdominal ultrasonogram showing the patient 's .\n",
      "within within within within within within within within within panoramic radiograph obtained at the first examination . only apical of the left upper central incisor was observed\n",
      "contours contours contours contours contours contours contours contours patient 's 6 months after the surgery\n"
     ]
    }
   ],
   "source": [
    "path_image_encoder = 'train/image_encoder.pth'\n",
    "path_semantic_encoder_path = 'train/semantic_encoder.pth'\n",
    "path_decoder_path = 'train/decoder.pth'\n",
    "# Initialize the caption generator and generate caption\n",
    "caption_generator = CaptionGenerator(vocab_file='vocab.pkl', embed_size=256, hidden_size=256, num_layers=1,\n",
    "                                        image_encoder_path=path_image_encoder,\n",
    "                                        semantic_encoder_path=path_semantic_encoder_path,\n",
    "                                        decoder_path=path_decoder_path)\n",
    "# image_path = \"selected_dataset/test/radiology/images/PMC4803869_GJHS-7-124-g006.jpg\"\n",
    "# caption = caption_generator.generate_caption(image_path)\n",
    "captions, GTs = caption_generator.process_batch(batch_size=4, max_seg_length=10)\n",
    "for caption, gt in zip(captions, GTs):\n",
    "    print(caption, gt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
